Configuring for 8 CPU threads

System Configuration:
--------------------------------------------------
OS: Linux 5.15.0-1089-azure
CPU: x86_64
Physical cores: 8
Total cores: 8
Max CPU frequency: 0MHz
Current CPU frequency: 2546MHz
RAM: Total=54.92GB, Available=45.06GB (18.0% used)

PyTorch version: 2.5.1
CUDA version: 12.4
--------------------------------------------------
Using devices: cpu, cpu, cpu

Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:02<00:02,  2.69s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  1.82s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  1.95s/it]

Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  1.39it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.54it/s]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.52it/s]

ðŸŽ¯ Running comprehensive benchmark with 5 diverse prompts...
ðŸ“ Test prompts: ['Short simple prompt', 'Medium recipe prompt', 'Long technical explanation', 'Creative writing prompt', 'Complex analytical prompt']

=== Benchmarking SkipLLaMA ===
Model device: cpu
Model dtype: torch.float32
Warming up model...

Running comprehensive benchmark on 5 prompts...

Prompt 1/5: Short simple prompt
Max tokens: 50
TTFT: 0.593s
Output TPS: 1.2
Total TPS: 1.3

Prompt 2/5: Medium recipe prompt
Max tokens: 200
TTFT: 0.626s
Output TPS: 0.5
Total TPS: 0.5

Prompt 3/5: Long technical explanation
Max tokens: 300
TTFT: 1.008s
Output TPS: 0.4
Total TPS: 0.4

Prompt 4/5: Creative writing prompt
Max tokens: 400
TTFT: 0.615s
Output TPS: 0.3
Total TPS: 0.3

Prompt 5/5: Complex analytical prompt
Max tokens: 500
TTFT: 0.738s
Output TPS: 0.2
Total TPS: 0.2

=== Benchmarking Standard LLaMA ===
Model device: cpu
Model dtype: torch.float32
Warming up model...

Running comprehensive benchmark on 5 prompts...

Prompt 1/5: Short simple prompt
Max tokens: 50
TTFT: 1.304s
Output TPS: 0.6
Total TPS: 0.7

Prompt 2/5: Medium recipe prompt
Max tokens: 200
TTFT: 1.147s
Output TPS: 0.3
Total TPS: 0.4

Prompt 3/5: Long technical explanation
Max tokens: 300
TTFT: 1.279s
Output TPS: 0.3
Total TPS: 0.3

Prompt 4/5: Creative writing prompt
Max tokens: 400
TTFT: 1.794s
Output TPS: 0.2
Total TPS: 0.2

Prompt 5/5: Complex analytical prompt
Max tokens: 500
TTFT: 1.184s
Output TPS: 0.2
Total TPS: 0.2

============================================================
ðŸ“Š SkipLLaMA Benchmark Results
============================================================
ðŸ“ˆ Performance Metrics (n=5 prompts):
----------------------------------------
âš¡ Time to First Token:
   P50: 0.626s
   P90: 0.900s
   Mean: 0.716s
ðŸš€ Output Generation Speed:
   P50: 0.4 tokens/sec
   P90: 0.9 tokens/sec
   Mean: 0.5 tokens/sec
ðŸ“Š Total Throughput:
   P50: 0.4 tokens/sec
   P90: 1.0 tokens/sec
   Mean: 0.6 tokens/sec

============================================================
ðŸ“Š Standard LLaMA Benchmark Results
============================================================
ðŸ“ˆ Performance Metrics (n=5 prompts):
----------------------------------------
âš¡ Time to First Token:
   P50: 1.279s
   P90: 1.598s
   Mean: 1.342s
ðŸš€ Output Generation Speed:
   P50: 0.3 tokens/sec
   P90: 0.5 tokens/sec
   Mean: 0.3 tokens/sec
ðŸ“Š Total Throughput:
   P50: 0.3 tokens/sec
   P90: 0.6 tokens/sec
   Mean: 0.4 tokens/sec

============================================================
ðŸ Performance Comparison
============================================================
âš¡ TTFT Speedup: 1.87x
ðŸš€ Output TPS Speedup: 1.59x
ðŸ“Š Total Throughput Speedup: 1.60x
